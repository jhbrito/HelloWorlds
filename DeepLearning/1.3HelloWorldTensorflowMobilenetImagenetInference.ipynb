{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "640rcV-0zQq0"
   },
   "source": [
    "# Hello World Mobilenet Imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWYjZweT35yB"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoLwTUMj3lUk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import PIL.Image as PImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_RES = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_14x4MjF4BRh"
   },
   "source": [
    "## Load Mobilenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm5Hf83s4EjS"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQMkJ9pJ4ghA"
   },
   "source": [
    "## Download and load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31K7YtWd4jzY"
   },
   "outputs": [],
   "source": [
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "\n",
    "image_path1  = tf.keras.utils.get_file('grace_hopper.jpg',  'https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
    "image1 = PImage.open(image_path1).resize((IMAGE_RES, IMAGE_RES))\n",
    "image_path2  = tf.keras.utils.get_file('STOP.jpg',  'https://upload.wikimedia.org/wikipedia/commons/f/f9/STOP_sign.jpg')\n",
    "image2 = PImage.open(image_path2).resize((IMAGE_RES, IMAGE_RES))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image1)\n",
    "plt.axis('off')\n",
    "_ = plt.title(\"Grace Hopper\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image2)\n",
    "plt.axis('off')\n",
    "_ = plt.title(\"Stop sign\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhDZetTg44Lt"
   },
   "source": [
    "## Use the model to predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = tf.keras.preprocessing.image.load_img(image_path1, target_size=(224, 224))\n",
    "x1 = tf.keras.preprocessing.image.img_to_array(image1)\n",
    "x1 = np.expand_dims(x1, axis=0)\n",
    "x1 = tf.keras.applications.mobilenet_v2.preprocess_input(x1)\n",
    "result1 = model.predict(x1)\n",
    "predicted_class_decoded1 = tf.keras.applications.mobilenet_v2.decode_predictions(result1, top=1)\n",
    "predicted_class_name1 = predicted_class_decoded1[0][0][1]\n",
    "predicted_class1 = np.argmax(result1[0], axis=-1)\n",
    "print(\"Class:\", predicted_class1)\n",
    "\n",
    "image2 = tf.keras.preprocessing.image.load_img(image_path2, target_size=(224, 224))\n",
    "x2 = tf.keras.preprocessing.image.img_to_array(image2)\n",
    "x2 = np.expand_dims(x2, axis=0)\n",
    "x2 = tf.keras.applications.mobilenet_v2.preprocess_input(x2)\n",
    "result2 = model.predict(x2)\n",
    "predicted_class_decoded2 = tf.keras.applications.mobilenet_v2.decode_predictions(result2, top=1)\n",
    "predicted_class_name2 = predicted_class_decoded2[0][0][1]\n",
    "predicted_class2 = np.argmax(result2[0], axis=-1)\n",
    "print(\"Class:\", predicted_class2)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image1)\n",
    "plt.axis('off')\n",
    "_ = plt.title(\"Prediction: \" + predicted_class_name1.title())\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image2)\n",
    "plt.axis('off')\n",
    "_ = plt.title(\"Prediction: \" + predicted_class_name2.title())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0OaOAv446U9"
   },
   "outputs": [],
   "source": [
    "x1 = np.array(image1)\n",
    "x2 = np.array(image2)\n",
    "print(\"x1.shape:\", x1.shape)\n",
    "x=np.zeros( (2,IMAGE_RES,IMAGE_RES,3))\n",
    "#x = x1[np.newaxis, ...]\n",
    "x[0] = x1\n",
    "x[1] = x2\n",
    "\n",
    "print(\"batch shape\", x.shape)\n",
    "#x = x / 255.0\n",
    "x = x / 255.0\n",
    "x = x * 2.0\n",
    "x = x - 1.0\n",
    "\n",
    "result = model.predict(x)\n",
    "print(result.shape)\n",
    "predicted_class1 = np.argmax(result[0], axis=-1)\n",
    "print(\"predicted_class1:\", predicted_class1)\n",
    "predicted_class2 = np.argmax(result[1], axis=-1)\n",
    "print(\"predicted_class2:\", predicted_class2)\n",
    "\n",
    "predicted_class_name1 = imagenet_labels[predicted_class1+1]\n",
    "print(\"predicted_class_name1:\", predicted_class_name1)\n",
    "predicted_class_name2= imagenet_labels[predicted_class2+1]\n",
    "print(\"predicted_class_name2:\", predicted_class_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMVsnP9Q6mPd"
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HelloWorldPython.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
