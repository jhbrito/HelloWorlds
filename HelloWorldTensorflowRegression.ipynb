{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht1UXsa1tTk9"
   },
   "source": [
    "# Hello World Tensorflow Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlKK8f7-tYNC"
   },
   "source": [
    "## Imports and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfPGs3tCtN8M"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Tensorflow {}\".format(tf.__version__))\n",
    "EPOCHS = 750\n",
    "n_samples=10\n",
    "mean_samples=20.0\n",
    "std_samples=5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3ZhOHOmtbIv"
   },
   "source": [
    "## Create some synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqbRsYT0teX_"
   },
   "outputs": [],
   "source": [
    "celsius = np.random.randn(n_samples)*std_samples+mean_samples\n",
    "fahrenheit = celsius * 1.8 + 32\n",
    "for i,c in enumerate(celsius):\n",
    "    print(\"{} degrees Celsius = {} degrees Fahrenheit\".format(c, fahrenheit[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnHyWShruxuC"
   },
   "source": [
    "This is what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMtmJBWQv3i4"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.scatter(celsius, fahrenheit, c='r', marker='x')\n",
    "ax.set_xlabel(\"Celsius\")\n",
    "ax.set_ylabel(\"Fahrenheit\")\n",
    "ax.set_title(\"Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a class to save the model parameters after every batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtolT1Mwt0d-"
   },
   "outputs": [],
   "source": [
    "class BatchLossHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.batch_losses = []\n",
    "        self.batch_weights = []\n",
    "        self.batch_biases = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.batch_losses.append(logs.get('loss'))\n",
    "        self.batch_weights.append(self.model.layers[0].trainable_weights[0][0,0].numpy())\n",
    "        self.batch_biases.append(self.model.layers[0].trainable_weights[1][0].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Na79J3LVtvsq"
   },
   "source": [
    "## Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-_cfPA7t_GY"
   },
   "outputs": [],
   "source": [
    "l0 = tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "model = tf.keras.Sequential([l0])\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\n",
    "l0_weights_init = l0.get_weights()\n",
    "print(\"Simple Model - layer variables init: {}\".format(l0_weights_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUT2yEjOuFk8"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_u_xuGpuE3h"
   },
   "outputs": [],
   "source": [
    "batch_history_simple = BatchLossHistory()\n",
    "history_simple = model.fit(celsius, fahrenheit, epochs=EPOCHS, callbacks=[batch_history_simple], verbose=False)\n",
    "print(\"Finished training the simple model \")\n",
    "l0_weights_end = l0.get_weights()\n",
    "print(\"Simple Model - Layer variables end: {}\".format(l0_weights_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [20.0]\n",
    "f = model.predict(c)\n",
    "print(\"Simple model predicts that 20 degrees Celsius is: {} degrees Fahrenheit\".format(f))\n",
    "f_gt = np.array(c) * 1.8 + 32\n",
    "print(\"Simple model error is: {} degrees Fahrenheit\".format(f-f_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXtKoBCbuMOg"
   },
   "source": [
    "### Analyse the model convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGJ6dQu8uOvh"
   },
   "outputs": [],
   "source": [
    "weight_history = batch_history_simple.batch_weights;\n",
    "bias_history = batch_history_simple.batch_biases;\n",
    "loss_history = batch_history_simple.batch_losses;\n",
    "\n",
    "half_range = 5\n",
    "weight = np.arange(1.8 - half_range, 1.8 + half_range, half_range/10.0)\n",
    "bias = np.arange(32 - half_range - 28, 32 + half_range, half_range/10.0)\n",
    "weight_grid_3D, bias_grid_3D, celsius_grid_3D = np.meshgrid(weight, bias, celsius)\n",
    "squared_error = ((celsius_grid_3D * weight_grid_3D + bias_grid_3D) - (celsius_grid_3D * 1.8 + 32))**2\n",
    "mean_squared_error = np.mean(squared_error, axis=2)\n",
    "weight_grid_2D, bias_grid_2D = np.meshgrid(weight, bias)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "# surf = ax.plot_surface(weight_grid_2D, bias_grid_2D, mean_squared_error, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "# ax.set_zlim(0.0, 20000.0)\n",
    "contour = ax.contour3D(weight_grid_2D, bias_grid_2D, mean_squared_error, 25, cmap=cm.coolwarm, antialiased=True)\n",
    "fig.colorbar(contour, shrink=0.5, aspect=5)\n",
    "line = ax.plot(weight_history, bias_history, loss_history, 'g-', linewidth=1, antialiased=False)\n",
    "scatter = ax.scatter([1.8], [32], [0], c='r', marker='.')\n",
    "ax.set_xlabel(\"Weight\")\n",
    "ax.set_ylabel(\"Bias\")\n",
    "ax.set_zlabel(\"Loss\")\n",
    "ax.set_title(\"Simple Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = tf.keras.layers.Dense(units=4, input_shape=[1])\n",
    "l1 = tf.keras.layers.Dense(units=4)\n",
    "l2 = tf.keras.layers.Dense(units=1)\n",
    "model = tf.keras.Sequential([l0, l1, l2])\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_history_complex = BatchLossHistory()\n",
    "history_complex = model.fit(celsius, fahrenheit, epochs=EPOCHS, callbacks=[batch_history_complex], verbose=False)\n",
    "print(\"Finished training the complex model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([20.0], dtype=float)\n",
    "f = model.predict(c)\n",
    "print(\"Complex model predicts that 20 degrees Celsius is: {} degrees Fahrenheit\".format(f))\n",
    "f_gt = np.array(c) * 1.8 + 32\n",
    "print(\"Complex model error is: {} degrees Fahrenheit\".format(f-f_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Complex model layer variables\")\n",
    "print(\" l0 variables: {}\".format(l0.get_weights()))\n",
    "print(\" l1 variables: {}\".format(l1.get_weights()))\n",
    "print(\" l2 variables: {}\".format(l2.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model with normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define normalization/denormalization functions and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(values):\n",
    "    values_std = np.std(values)\n",
    "    values_mean = np.mean(values)\n",
    "    values_n = (values-values_mean)/values_std\n",
    "    return (values_n, values_mean, values_std)\n",
    "\n",
    "def denormalize(values_n, values_mean, values_std):\n",
    "    values_u = values_n*values_std+values_mean\n",
    "    return values_u\n",
    "\n",
    "celsius_n, celsius_mean, celsius_std  = normalize(celsius)\n",
    "fahrenheit_n, fahrenheit_mean, fahrenheit_std  = normalize(fahrenheit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0_n = tf.keras.layers.Dense(units=1, input_shape=[1])\n",
    "model_n = tf.keras.Sequential([l0_n])\n",
    "model_n.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1) )\n",
    "l0_weights_n_init = l0_n.get_weights()\n",
    "print(\"Normalized Model - layer variables init: {}\".format(l0_weights_n_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_history_normalized = BatchLossHistory()\n",
    "history_simple_normalized = model_n.fit(celsius_n, fahrenheit_n, epochs=EPOCHS, callbacks=[batch_history_normalized], verbose=False)\n",
    "print(\"Finished training the simple model with normalized data\")\n",
    "l0_weights_n_end = l0_n.get_weights()\n",
    "print(\"Normalized Model - Layer variables end: {}\".format(l0_weights_n_end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [20.0]\n",
    "f_gt = np.array(c) * 1.8 + 32\n",
    "c=(c-celsius_mean)/celsius_std\n",
    "f=model_n.predict(c)\n",
    "f=denormalize(f, fahrenheit_mean, fahrenheit_std)\n",
    "print(\"Normalized model predicts that 20 degrees Celsius is: {} degrees Fahrenheit\".format(f))\n",
    "print(\"Normalized model error is: {} degrees Fahrenheit\".format(f-f_gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise model convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_history_n = batch_history_normalized.batch_weights;\n",
    "bias_history_n = batch_history_normalized.batch_biases;\n",
    "loss_history_n = batch_history_normalized.batch_losses;\n",
    "\n",
    "weight_n = np.arange(1 - 0.5, 1 + 0.5, 0.01)\n",
    "bias_n = np.arange(0 - 0.5, 0 + 0.5, 0.01)\n",
    "weight_grid_3D_n, bias_grid_3D_n, celsius_grid_3D_n = np.meshgrid(weight_n, bias_n, celsius_n)\n",
    "\n",
    "squared_error_n = ( (celsius_grid_3D_n * weight_grid_3D_n + bias_grid_3D_n) - ((denormalize(celsius_grid_3D_n, celsius_mean,  celsius_std ) * 1.8 + 32 - fahrenheit_mean)/fahrenheit_std) )**2\n",
    "mean_squared_error_n = np.mean(squared_error_n, axis=2)\n",
    "weight_grid_2D_n, bias_grid_2D_n = np.meshgrid(weight_n, bias_n)\n",
    "\n",
    "fig = plt.figure(2)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "ax.set_xlim(0.5, 1.5)\n",
    "ax.set_ylim(-0.5, 0.5)\n",
    "ax.set_zlim(0.0, 0.5)\n",
    "\n",
    "contour = ax.contour3D(weight_grid_2D_n, bias_grid_2D_n, mean_squared_error_n, 25, cmap=cm.coolwarm, antialiased=True)\n",
    "fig.colorbar(contour, shrink=0.5, aspect=5)\n",
    "line = ax.plot(weight_history_n, bias_history_n, loss_history_n, 'g-', linewidth=1)\n",
    "# line = ax.scatter(weight_history_n, bias_history_n, loss_history_n, cmap=cm.coolwarm, linewidth=1)\n",
    "scatter = ax.scatter([1], [0], [0], c='r', marker='.')\n",
    "ax.set_xlabel(\"Normalized Weight\")\n",
    "ax.set_ylabel(\"Normalized Bias\")\n",
    "ax.set_zlabel(\"Normalized Loss\")\n",
    "ax.set_title(\"Normalized Model\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model convergences (loss vs epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(history_simple.history['loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel(\"Loss Magnitude\")\n",
    "plt.title(\"Simple Model\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(history_complex.history['loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel(\"Loss Magnitude\")\n",
    "plt.title(\"Complex Model\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(history_simple_normalized.history['loss'])\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel(\"Loss Magnitude\")\n",
    "plt.title(\"Normalized Model\")\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HelloWorldTensorflowRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
